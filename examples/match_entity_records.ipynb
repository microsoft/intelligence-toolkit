{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import polars as pl\n",
    "\n",
    "from toolkit.match_entity_records.prepare_model import (\n",
    "    build_attribute_options,\n",
    "    format_dataset,\n",
    ")\n",
    "\n",
    "# Load data\n",
    "df1 = pl.read_csv(\"file1.csv\")\n",
    "df2 = pl.read_csv(\"file2.csv\")\n",
    "\n",
    "# add dataset already with name, entity name, maybe id and attr columns\n",
    "\n",
    "matching_dfs = {}\n",
    "matching_dfs[\"file1\"] = format_dataset(\n",
    "    df1, [\" JoinDate\", \" Salary  \", \"EmployeeID\"], \" FullName\"\n",
    ")\n",
    "matching_dfs[\"file2\"] = format_dataset(\n",
    "    df2, [\" Start_Date\", \" Budget  \", \"ProjID\"], \" TeamLead\"\n",
    ")\n",
    "\n",
    "attr_options = build_attribute_options(matching_dfs)\n",
    "attr_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.match_entity_records.prepare_model import build_attribute_list\n",
    "from toolkit.match_entity_records.config import AttributeToMatch\n",
    "\n",
    "\n",
    "attributes = [\n",
    "    AttributeToMatch(\n",
    "        {\n",
    "            \"label\": \" JoinDate\",\n",
    "            \"columns\": [\" JoinDate::file1\", \" Start_Date::file2\"],\n",
    "        },\n",
    "    )\n",
    "]\n",
    "\n",
    "atts_to_datasets = build_attribute_list(attributes)\n",
    "atts_to_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.match_entity_records.detect import build_attributes_dataframe\n",
    "\n",
    "\n",
    "merged_df = build_attributes_dataframe(\n",
    "    matching_dfs,\n",
    "    atts_to_datasets,\n",
    ")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.with_columns(\n",
    "    ((pl.col(\"Entity ID\").cast(pl.Utf8)) + \"::\" + pl.col(\"Dataset\")).alias(\"Unique ID\")\n",
    ")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from toolkit.AI.openai_embedder import OpenAIEmbedder\n",
    "from toolkit.AI.openai_configuration import OpenAIConfiguration\n",
    "from toolkit.match_entity_records.detect import convert_to_sentences\n",
    "\n",
    "ai_configuration = OpenAIConfiguration(\n",
    "    {\n",
    "        \"api_type\": \"OpenAI\",\n",
    "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "        \"model\": \"gpt-4o-2024-08-06\",\n",
    "    }\n",
    ")\n",
    "\n",
    "text_embedder = OpenAIEmbedder(\n",
    "    configuration=ai_configuration,\n",
    ")\n",
    "\n",
    "all_sentences = convert_to_sentences(merged_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    embedding_data = await text_embedder.embed_store_many(all_sentences)\n",
    "    print(len(embedding_data), \" embedding_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build scores and map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.match_entity_records.detect import (\n",
    "    build_near_map,\n",
    "    build_nearest_neighbors,\n",
    "    build_sentence_pair_scores,\n",
    ")\n",
    "\n",
    "embeddings = [embedding[\"vector\"] for embedding in embedding_data]\n",
    "\n",
    "distances, indices = build_nearest_neighbors(embeddings)\n",
    "\n",
    "sentence_pair_embedding_threshold = 0.05\n",
    "near_map = build_near_map(\n",
    "    distances,\n",
    "    indices,\n",
    "    all_sentences,\n",
    "    sentence_pair_embedding_threshold,\n",
    ")\n",
    "\n",
    "sentence_pair_scores = build_sentence_pair_scores(near_map, merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.match_entity_records.detect import build_matches, build_matches_dataset\n",
    "\n",
    "matching_sentence_pair_jaccard_threshold = 0.75\n",
    "entity_to_group, matches, pair_to_match = build_matches(\n",
    "    sentence_pair_scores, merged_df, matching_sentence_pair_jaccard_threshold\n",
    ")\n",
    "\n",
    "matches_df_final = pl.DataFrame(\n",
    "    list(matches),\n",
    "    schema=[\"Group ID\", *merged_df.columns],\n",
    ").sort(by=[\"Group ID\", \"Entity name\", \"Dataset\"], descending=False)\n",
    "\n",
    "matches_df_final = build_matches_dataset(\n",
    "    matches_df_final, pair_to_match, entity_to_group\n",
    ")\n",
    "\n",
    "print(matches_df_final.shape[0], \"matches\")\n",
    "print(matches_df_final[\"Group ID\"].n_unique(), \"groups formed\")\n",
    "print(matches_df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from toolkit.AI.openai_configuration import OpenAIConfiguration\n",
    "from toolkit.AI.client import OpenAIClient\n",
    "from toolkit.match_entity_records.model import (\n",
    "    prepare_for_ai_report,\n",
    ")\n",
    "\n",
    "batch_messages = prepare_for_ai_report(matches_df_final)\n",
    "print(batch_messages)\n",
    "\n",
    "ai_configuration = OpenAIConfiguration(\n",
    "    {\n",
    "        \"api_type\": \"OpenAI\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        \"model\": \"gpt-4o-2024-08-06\",\n",
    "    }\n",
    ")\n",
    "\n",
    "unique_names = matches_df_final[\"Entity name\"].unique()\n",
    "prefix = \"```\\nGroup ID,Relatedness,Explanation\\n\"\n",
    "for messages in batch_messages:\n",
    "    response = OpenAIClient(ai_configuration).generate_chat(messages, stream=False)\n",
    "    if len(response.strip()) > 0:\n",
    "        prefix = prefix + response + \"\\n\"\n",
    "\n",
    "result = prefix.replace(\"```\\n\", \"\").strip()\n",
    "lines = result.split(\"\\n\")\n",
    "\n",
    "if len(lines) > 30:\n",
    "    lines = lines[:30]\n",
    "    result = \"\\n\".join(lines)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
