{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import importlib\n",
    "import asyncio\n",
    "import python.question_answering.process_inputs as process_inputs\n",
    "import python.question_answering.generate_answer as generate_answer\n",
    "import python.AI.embedder\n",
    "import python.AI.client\n",
    "from python.AI.embedder import Embedder\n",
    "from python.AI.openai_configuration import OpenAIConfiguration\n",
    "from python.helpers.constants import CACHE_PATH\n",
    "importlib.reload(process_inputs)\n",
    "importlib.reload(generate_answer)\n",
    "importlib.reload(python.AI.embedder)\n",
    "importlib.reload(python.AI.client)\n",
    "import newspaper # pip install newspaper3k, pip install lxml_html_clean\n",
    "import nest_asyncio # pip install nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_news = 'https://www.bbc.com/news/articles'\n",
    "target_articles = 50\n",
    "target_chars = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = newspaper.build(target_news, language='en', memoize_articles=False)\n",
    "article_texts = {}\n",
    "for article in news.articles:\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    title = article.title\n",
    "    text = article.text\n",
    "    if len(text) >= target_chars:\n",
    "        article_texts[title] = text\n",
    "        print(f'Processed {len(article_texts)} articles')\n",
    "    if len(article_texts) == target_articles:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_configuration = OpenAIConfiguration({\n",
    "    \"api_type\": \"OpenAI\",\n",
    "    \"api_key\": os.environ['OPENAI_API_KEY'],\n",
    "    \"model\": \"gpt-4o-2024-08-06\",\n",
    "})\n",
    "\n",
    "text_embedder = Embedder(\n",
    "    configuration=ai_configuration,\n",
    "    pickle_path=CACHE_PATH,\n",
    "    local=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_to_chunks = process_inputs.process_texts(article_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    text_to_vectors,\n",
    "    concept_graph,\n",
    "    community_to_concepts,\n",
    "    concept_to_community,\n",
    "    concept_to_chunks,\n",
    "    chunk_to_concepts,\n",
    "    previous_chunk,\n",
    "    next_chunk\n",
    ") = process_inputs.process_chunks(\n",
    "    text_to_chunks=title_to_chunks,\n",
    "    embedder=text_embedder,\n",
    "    embedding_cache=CACHE_PATH,\n",
    "    max_cluster_size=25\n",
    ")\n",
    "print(f'Processed chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What events are discussed?\"\n",
    "\n",
    "async def answer():\n",
    "    relevant_chunks, partial_answers, chunk_progress, answer_progress = generate_answer.answer_question(\n",
    "        ai_configuration=ai_configuration,\n",
    "        question=question,\n",
    "        text_to_chunks=title_to_chunks,\n",
    "        chunk_to_concepts=chunk_to_concepts,\n",
    "        concept_to_chunks=concept_to_chunks,\n",
    "        text_to_vectors=text_to_vectors,\n",
    "        community_to_concepts=community_to_concepts,\n",
    "        concept_to_community=concept_to_community,\n",
    "        previous_chunk=previous_chunk,\n",
    "        next_chunk=next_chunk,\n",
    "        embedder=text_embedder,\n",
    "        embedding_cache=CACHE_PATH,\n",
    "        select_logit_bias=5,\n",
    "        semantic_search_depth=5,\n",
    "        structural_search_steps=1,\n",
    "        relational_search_depth=5,\n",
    "        relevance_test_limit=20,\n",
    "        relevance_test_batch_size=5,\n",
    "        answer_batch_size=5,\n",
    "        augment_top_concepts=10\n",
    "    )\n",
    "    return relevant_chunks, partial_answers, chunk_progress, answer_progress\n",
    "\n",
    "relevant_chunks, partial_answers, chunk_progress, answer_progress = asyncio.run(answer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = partial_answers[0]\n",
    "print(final_answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
