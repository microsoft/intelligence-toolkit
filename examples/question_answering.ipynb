{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.append('..')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import asyncio\n",
                "from toolkit.AI.openai_configuration import OpenAIConfiguration\n",
                "from toolkit.AI.openai_embedder import OpenAIEmbedder\n",
                "from toolkit.helpers.constants import CACHE_PATH\n",
                "\n",
                "import toolkit.question_answering.input_processor as input_processor\n",
                "import toolkit.question_answering.question_answerer as question_answerer\n",
                "import toolkit.AI.client\n",
                "import toolkit.question_answering.graph_builder\n",
                "import toolkit.question_answering.answer_builder\n",
                "\n",
                "import newspaper # pip install newspaper3k lxml_html_clean\n",
                "import nest_asyncio # pip install nest_asyncio\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_news = 'https://www.bbc.com/news/articles'\n",
                "target_articles = 50\n",
                "target_chars = 1000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "news = newspaper.build(target_news, language='en', memoize_articles=False)\n",
                "article_text_jsons = []\n",
                "for article in news.articles:\n",
                "    article.download()\n",
                "    article.parse()\n",
                "    title = article.title\n",
                "    text = article.text\n",
                "    article_text_json = {}\n",
                "    if len(text) >= target_chars:\n",
                "        article_text_json['title'] = title\n",
                "        article_text_json['text'] = text\n",
                "        article_text_jsons.append(article_text_json)\n",
                "        print(f'Processed {len(article_text_jsons)} articles')\n",
                "    if len(article_text_jsons) == target_articles:\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai_configuration = OpenAIConfiguration({\n",
                "    \"api_type\": \"OpenAI\",\n",
                "    \"api_key\": os.environ['OPENAI_API_KEY'],\n",
                "    \"model\": \"gpt-4o-2024-08-06\",\n",
                "})\n",
                "\n",
                "text_embedder = OpenAIEmbedder(\n",
                "    configuration=ai_configuration,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "title_to_chunks = input_processor.process_json_texts(article_text_jsons)\n",
                "title_to_chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(\n",
                "    text_to_vectors,\n",
                "    concept_graph,\n",
                "    community_to_concepts,\n",
                "    concept_to_community,\n",
                "    concept_to_chunks,\n",
                "    chunk_to_concepts,\n",
                "    previous_chunk,\n",
                "    next_chunk\n",
                ") = input_processor.process_chunks(\n",
                "    text_to_chunks=title_to_chunks,\n",
                "    embedder=text_embedder,\n",
                "    embedding_cache=CACHE_PATH,\n",
                "    max_cluster_size=25\n",
                ")\n",
                "print(f'Processed chunks')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "question = \"What events are discussed?\"\n",
                "\n",
                "async def answer():\n",
                "    relevant_chunks, partial_answers, chunk_progress, answer_progress = question_answerer.answer_question(\n",
                "        ai_configuration=ai_configuration,\n",
                "        question=question,\n",
                "        text_to_chunks=title_to_chunks,\n",
                "        chunk_to_concepts=chunk_to_concepts,\n",
                "        concept_to_chunks=concept_to_chunks,\n",
                "        text_to_vectors=text_to_vectors,\n",
                "        concept_graph=concept_graph,\n",
                "        community_to_concepts=community_to_concepts,\n",
                "        concept_to_community=concept_to_community,\n",
                "        previous_chunk=previous_chunk,\n",
                "        next_chunk=next_chunk,\n",
                "        embedder=text_embedder,\n",
                "        embedding_cache=CACHE_PATH,\n",
                "        select_logit_bias=5,\n",
                "        semantic_search_depth=5,\n",
                "        structural_search_steps=1,\n",
                "        community_search_breadth=5,\n",
                "        relevance_test_limit=20,\n",
                "        relevance_test_batch_size=5,\n",
                "        answer_batch_size=5,\n",
                "        augment_top_concepts=10\n",
                "    )\n",
                "    return relevant_chunks, partial_answers, chunk_progress, answer_progress\n",
                "\n",
                "relevant_chunks, partial_answers, chunk_progress, answer_progress = asyncio.run(answer())\n",
                "print(f'Answered question')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(chunk_progress)\n",
                "print(answer_progress)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_answer = partial_answers[0]\n",
                "print(final_answer)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
