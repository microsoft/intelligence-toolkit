{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "\n",
                "sys.path.append(\"..\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import asyncio\n",
                "from toolkit.AI.openai_configuration import OpenAIConfiguration\n",
                "from toolkit.AI.openai_embedder import OpenAIEmbedder\n",
                "from toolkit.helpers.constants import CACHE_PATH\n",
                "\n",
                "import toolkit.query_text_data.input_processor as input_processor\n",
                "import toolkit.query_text_data.question_answerer as question_answerer\n",
                "import toolkit.query_text_data.pattern_detector as pattern_detector\n",
                "import toolkit.graph.graph_fusion_encoder_embedding as gfee\n",
                "import toolkit.query_text_data.helper_functions as helper_functions\n",
                "\n",
                "import newspaper  # poetry add newspaper3k lxml_html_clean\n",
                "import nest_asyncio  # poetry add nest_asyncio\n",
                "\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment the following lines to access library code updates\n",
                "# import importlib\n",
                "# importlib.reload(input_processor)\n",
                "# importlib.reload(pattern_detector)\n",
                "# importlib.reload(helper_functions)\n",
                "# importlib.reload(question_answerer)\n",
                "# importlib.reload(gfee)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "newspaper.popular_urls()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_news = \"https://www.cnn.com\"\n",
                "target_articles = 50\n",
                "target_chars = 1000"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "news = newspaper.build(target_news, language=\"en\", memoize_articles=False)\n",
                "file_to_text_json = {}\n",
                "for article in news.articles:\n",
                "    article.download()\n",
                "    article.parse()\n",
                "    title = article.title\n",
                "    text = article.text\n",
                "    article_text_json = {}\n",
                "    timestamp = article.publish_date.isoformat() if article.publish_date else None\n",
                "    if timestamp != None and len(text) >= target_chars:\n",
                "        article_text_json[\"title\"] = title\n",
                "        article_text_json[\"timestamp\"] = timestamp\n",
                "        article_text_json[\"text\"] = text\n",
                "        file_to_text_json[title] = article_text_json\n",
                "        print(f\"Processed {len(file_to_text_json)} articles\")\n",
                "    if len(file_to_text_json) == target_articles:\n",
                "        break"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ai_configuration = OpenAIConfiguration(\n",
                "    {\n",
                "        \"api_type\": \"OpenAI\",\n",
                "        \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
                "        \"model\": \"gpt-4o-2024-08-06\",\n",
                "    }\n",
                ")\n",
                "\n",
                "text_embedder = OpenAIEmbedder(\n",
                "    configuration=ai_configuration,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "window_period = input_processor.PeriodOption.DAY\n",
                "file_to_chunks = input_processor.process_json_texts(file_to_text_json, window_period)\n",
                "file_to_chunks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "(\n",
                "    cid_to_text,\n",
                "    text_to_cid,\n",
                "    period_concept_graphs,\n",
                "    community_to_concepts,\n",
                "    concept_to_community,\n",
                "    concept_to_cids,\n",
                "    cid_to_concepts,\n",
                "    previous_cid,\n",
                "    next_cid,\n",
                "    period_to_cids,\n",
                "    node_period_counts,\n",
                "    edge_period_counts,\n",
                ") = input_processor.process_chunks(file_to_chunks=file_to_chunks, max_cluster_size=25)\n",
                "print(f\"Processed chunks\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "node_to_period_to_pos = None\n",
                "node_to_period_to_shift = None\n",
                "if window_period != input_processor.PeriodOption.NONE:\n",
                "    node_to_period_to_pos, node_to_period_to_shift = (\n",
                "        gfee.generate_graph_fusion_encoder_embedding(\n",
                "            period_to_graph=period_concept_graphs,\n",
                "            node_to_label=concept_to_community,\n",
                "            correlation=True,\n",
                "            diaga=True,\n",
                "            laplacian=True,\n",
                "        )\n",
                "    )\n",
                "print(f\"Generated graph fusion encoder embedding\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cid_to_converging_pairs = None\n",
                "if window_period != input_processor.PeriodOption.NONE:\n",
                "    cid_to_converging_pairs = pattern_detector.detect_converging_pairs(\n",
                "        period_to_cids,\n",
                "        cid_to_concepts,\n",
                "        node_to_period_to_pos,\n",
                "    )\n",
                "print(f\"Detected converging pairs\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cid_to_summary = None\n",
                "if window_period != input_processor.PeriodOption.NONE:\n",
                "    cid_to_summary = pattern_detector.explain_chunk_significance(\n",
                "        period_to_cids,\n",
                "        cid_to_converging_pairs,\n",
                "        node_period_counts,\n",
                "        edge_period_counts,\n",
                "    )\n",
                "print(f\"Explained chunk significance\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cid_to_explained_text = cid_to_text\n",
                "if window_period != input_processor.PeriodOption.NONE:\n",
                "    cid_to_explained_text = pattern_detector.combine_chunk_text_and_explantion(\n",
                "        cid_to_text, cid_to_summary\n",
                "    )\n",
                "print(f\"Combined chunk text and explanation\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cid_to_vector = await helper_functions.embed_texts(\n",
                "    cid_to_text=cid_to_explained_text,\n",
                "    text_embedder=text_embedder,\n",
                ")\n",
                "print(f\"Embedded chunk text\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "question = \"What events are discussed?\"\n",
                "\n",
                "\n",
                "async def answer():\n",
                "    (\n",
                "        relevant_cids,\n",
                "        partial_answers,\n",
                "        chunk_progress,\n",
                "        answer_progress,\n",
                "    ) = await question_answerer.answer_question(\n",
                "        ai_configuration=ai_configuration,\n",
                "        question=question,\n",
                "        cid_to_text=cid_to_explained_text,\n",
                "        cid_to_concepts=cid_to_concepts,\n",
                "        concept_to_cids=concept_to_cids,\n",
                "        cid_to_vector=cid_to_vector,\n",
                "        concept_graph=period_concept_graphs[\"ALL\"],\n",
                "        community_to_concepts=community_to_concepts,\n",
                "        concept_to_community=concept_to_community,\n",
                "        previous_cid=previous_cid,\n",
                "        next_cid=next_cid,\n",
                "        embedder=text_embedder,\n",
                "        embedding_cache=CACHE_PATH,\n",
                "        select_logit_bias=5,\n",
                "        adjacent_search_steps=1,\n",
                "        relevance_test_budget=10,\n",
                "        community_relevance_tests=5,\n",
                "        relevance_test_batch_size=5,\n",
                "        irrelevant_community_restart=3,\n",
                "        answer_batch_size=10,\n",
                "    )\n",
                "    return relevant_cids, partial_answers, chunk_progress, answer_progress\n",
                "\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    relevant_cids, partial_answers, chunk_progress, answer_progress = await answer()\n",
                "    print(f\"Answered question\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(chunk_progress)\n",
                "print(answer_progress)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "final_answer = partial_answers[0]\n",
                "print(final_answer)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
